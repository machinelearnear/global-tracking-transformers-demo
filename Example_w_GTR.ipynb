{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6879575-20de-4a07-85be-faffd7f97c1f",
   "metadata": {},
   "source": [
    "# Global Tracking Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d6409-853a-4630-a3e9-abe3f043d28d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "- Linux or macOS with Python ≥ 3.6\n",
    "- PyTorch ≥ 1.8.\n",
    "  Install them together at [pytorch.org](https://pytorch.org) to make sure of this. Note, please check\n",
    "  PyTorch version matches that is required by Detectron2.\n",
    "- Detectron2: follow [Detectron2 installation instructions](https://detectron2.readthedocs.io/tutorials/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5315f2e-269c-4a26-9ce2-90f228c617fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import detectron2\n",
    "except ImportError:\n",
    "    import torch\n",
    "    TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "    CUDA_VERSION = torch.__version__.split(\"+\")[-1] if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"Detectron2 not found. Installing now..\")\n",
    "    !python -m pip install detectron2 -f \\\n",
    "        https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a7a533-afe2-4a66-a9ca-962bc0ade807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GTR'...\n",
      "remote: Enumerating objects: 128, done.\u001b[K\n",
      "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
      "remote: Compressing objects: 100% (104/104), done.\u001b[Kpressing objects:   5% (6/104)\u001b[K\n",
      "remote: Total 128 (delta 21), reused 126 (delta 19), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (128/128), 2.66 MiB | 26.96 MiB/s, done.\n",
      "Resolving deltas: 100% (21/21), done.\n",
      "Submodule 'third_party/CenterNet2' (https://github.com/xingyizhou/CenterNet2) registered for path 'third_party/CenterNet2'\n",
      "Cloning into '/home/studio-lab-user/global-tracking-transformers-demo/GTR/third_party/CenterNet2'...\n",
      "remote: Enumerating objects: 13905, done.        \n",
      "remote: Counting objects: 100% (3017/3017), done.        \n",
      "remote: Compressing objects: 100% (1300/1300), done.        \n",
      "remote: Total 13905 (delta 1997), reused 2437 (delta 1698), pack-reused 10888        \n",
      "Receiving objects: 100% (13905/13905), 5.70 MiB | 27.67 MiB/s, done.\n",
      "Resolving deltas: 100% (9890/9890), done.\n",
      "Submodule path 'third_party/CenterNet2': checked out '42f422b3c3fe35ca4700d9bdf1c45e843c77d4cd'\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists as path_exists\n",
    "if not path_exists('GTR'):\n",
    "    !git clone https://github.com/xingyizhou/GTR.git --recurse-submodules\n",
    "    # !curl https://www.dropbox.com/s/eufigxmmkv5woop/RealBasicVSR.pth?dl=0 --create-dirs -o $ModelWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d3c08-81ea-4c0a-87af-5e8473ff2315",
   "metadata": {},
   "source": [
    "## Run demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7097a361-4aa1-4833-862b-64a516bbe3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'GTR' not in os.getcwd(): os.chdir('GTR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42f73312-4d53-4d83-a0fc-40b6db32bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from faulthandler import disable\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "import warnings\n",
    "import cv2\n",
    "import tqdm\n",
    "import sys\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.colormap import *\n",
    "\n",
    "sys.path.insert(0, 'third_party/CenterNet2/projects/CenterNet2/')\n",
    "from centernet.config import add_centernet_config\n",
    "from gtr.config import add_gtr_config\n",
    "\n",
    "from gtr.predictor import VisualizationDemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9eb26d8-84be-4e60-86fe-a0923e5bda27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ababbe1-c7bd-413d-b8c3-04ab8eab3eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import importlib.resources as pkg_resources\n",
    "except ImportError:\n",
    "    # Try backported to PY<37 `importlib_resources`.\n",
    "    import importlib_resources as pkg_resources\n",
    "\n",
    "from detectron2 import utils\n",
    "\n",
    "template = pkg_resources.read_text(utils, 'colormap.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65b1f827-873f-44bb-af08-9a2d30996c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.colormap import _COLORS\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87acac40-989d-49ad-b370-e66dd8038517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_colors(N, rgb=False, maximum=255):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        N (int): number of unique colors needed\n",
    "        rgb (bool): whether to return RGB colors or BGR colors.\n",
    "        maximum (int): either 255 or 1\n",
    "    Returns:\n",
    "        ndarray: a list of random_color\n",
    "    \"\"\"\n",
    "    indices = random.sample(range(len(_COLORS)), N)\n",
    "    ret = [_COLORS[i] * maximum for i in indices]\n",
    "    if not rgb:\n",
    "        ret = [x[::-1] for x in ret]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24ce5f32-382c-4126-ad1a-999ea8f090ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_cfg(args):\n",
    "    cfg = get_cfg()\n",
    "    if args.cpu:\n",
    "        cfg.MODEL.DEVICE=\"cpu\"\n",
    "    add_centernet_config(cfg)\n",
    "    add_gtr_config(cfg)\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    # Set score_threshold for builtin models\n",
    "    cfg.MODEL.RETINANET.SCORE_THRESH_TEST = args.confidence_threshold\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = args.confidence_threshold\n",
    "    cfg.freeze()\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c1cd361-d644-4c0e-a172-82769235c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_opencv_video_format(codec, file_ext):\n",
    "    with tempfile.TemporaryDirectory(prefix=\"video_format_test\") as dir:\n",
    "        filename = os.path.join(dir, \"test_file\" + file_ext)\n",
    "        writer = cv2.VideoWriter(\n",
    "            filename=filename,\n",
    "            fourcc=cv2.VideoWriter_fourcc(*codec),\n",
    "            fps=float(30),\n",
    "            frameSize=(10, 10),\n",
    "            isColor=True,\n",
    "        )\n",
    "        [writer.write(np.zeros((10, 10, 3), np.uint8)) for _ in range(30)]\n",
    "        writer.release()\n",
    "        if os.path.isfile(filename):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "398421fc-395b-482d-8bc4-98dca2adc6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "WINDOW_NAME = \"GTR\"\n",
    "\n",
    "class args:\n",
    "    config_file = \"configs/GTR_TAO_DR2101.yaml\"\n",
    "    confidence_threshold = 0.5\n",
    "    cpu = True\n",
    "    input = None\n",
    "    video_input = 'docs/yfcc_v_acef1cb6d38c2beab6e69e266e234f.mp4'\n",
    "    output = 'output/demo_yfcc.mp4'\n",
    "    opts = ['MODEL.WEIGHTS','models/GTR_TAO_DR2101.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f6d7f09-825b-4ef7-bcc5-01d3e1e6ec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/27 23:03:12 detectron2]: \u001b[0mArguments: <class '__main__.args'>\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/27 23:03:12 d2.config.compat]: \u001b[0mConfig 'configs/GTR_TAO_DR2101.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "\u001b[32m[03/27 23:03:14 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from models/GTR_TAO_DR2101.pth ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/27 23:03:15 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.0.freq_weight\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.1.freq_weight\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.2.freq_weight\u001b[0m\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/27 23:03:15 fvcore.common.checkpoint]: \u001b[0mThe checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mroi_heads.pos_emb.weight\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x34363278/'x264' is not supported with codec id 27 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x31637661/'avc1'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'random_colors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     output_file \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(\n\u001b[1;32m     56\u001b[0m         filename\u001b[38;5;241m=\u001b[39moutput_fname,\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# some installation of opencv may not support x264 (due to its license),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m         isColor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     63\u001b[0m     )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(args\u001b[38;5;241m.\u001b[39mvideo_input)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vis_frame \u001b[38;5;129;01min\u001b[39;00m demo\u001b[38;5;241m.\u001b[39mrun_on_video(video):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39moutput:\n\u001b[1;32m     67\u001b[0m         output_file\u001b[38;5;241m.\u001b[39mwrite(vis_frame)\n",
      "File \u001b[0;32m~/global-tracking-transformers-demo/GTR/gtr/predictor.py:144\u001b[0m, in \u001b[0;36mVisualizationDemo.run_on_video\u001b[0;34m(self, video)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_on_video\u001b[39m(\u001b[38;5;28mself\u001b[39m, video):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     tracker_visualizer \u001b[38;5;241m=\u001b[39m \u001b[43mTrackingVisualizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     frames \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame_from_video(video)]\n\u001b[1;32m    146\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_predictor(frames)\n",
      "File \u001b[0;32m~/global-tracking-transformers-demo/GTR/gtr/predictor.py:26\u001b[0m, in \u001b[0;36mTrackingVisualizer.__init__\u001b[0;34m(self, metadata, instance_mode)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_num_instances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m74\u001b[39m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_color_pool \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_colors\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_colors, rgb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, maximum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_colors' is not defined"
     ]
    }
   ],
   "source": [
    "mp.set_start_method(\"spawn\", force=True)\n",
    "# args = get_parser().parse_args()\n",
    "setup_logger(name=\"fvcore\")\n",
    "logger = setup_logger()\n",
    "logger.info(\"Arguments: \" + str(args))\n",
    "\n",
    "cfg = setup_cfg(args)\n",
    "demo = VisualizationDemo(cfg)\n",
    "\n",
    "if args.input: # image folder\n",
    "    if len(args.input) == 1:\n",
    "        args.input = glob.glob(os.path.expanduser(args.input[0]))\n",
    "        assert args.input, \"The input path(s) was not found\"\n",
    "    assert len(args.input) > 1, \"Input must be more than one image\"\n",
    "    args.input = sorted(args.input)\n",
    "    frames = []\n",
    "    for path in args.input:\n",
    "        img = read_image(path, format=\"BGR\")\n",
    "        frames.append(img)\n",
    "\n",
    "    for path, visualized_output in zip(\n",
    "        args.input, demo.run_on_images(frames)):\n",
    "        if args.output:\n",
    "            if not os.path.exists(args.output):\n",
    "                os.mkdir(args.output)\n",
    "            out_filename = os.path.join(args.output, os.path.basename(path))\n",
    "            cv2.imwrite(out_filename, visualized_output)\n",
    "        else:\n",
    "            cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow(WINDOW_NAME, visualized_output)\n",
    "            if cv2.waitKey(0) == 27:\n",
    "                break  # esc to quit\n",
    "elif args.video_input:\n",
    "    video = cv2.VideoCapture(args.video_input)\n",
    "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
    "    num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    basename = os.path.basename(args.video_input)\n",
    "    codec, file_ext = (\n",
    "        (\"x264\", \".mkv\") if test_opencv_video_format(\"x264\", \".mkv\") else (\"mp4v\", \".mp4\")\n",
    "    )\n",
    "    if codec == \".mp4v\":\n",
    "        warnings.warn(\"x264 codec not available, switching to mp4v\")\n",
    "    if args.output:\n",
    "        if os.path.isdir(args.output):\n",
    "            output_fname = os.path.join(args.output, basename)\n",
    "            output_fname = os.path.splitext(output_fname)[0] + file_ext\n",
    "        else:\n",
    "            folder_name = os.path.dirname(args.output)\n",
    "            if not os.path.exists(folder_name):\n",
    "                os.makedirs(folder_name)\n",
    "            output_fname = args.output\n",
    "        # assert not os.path.isfile(output_fname), output_fname\n",
    "        output_file = cv2.VideoWriter(\n",
    "            filename=output_fname,\n",
    "            # some installation of opencv may not support x264 (due to its license),\n",
    "            # you can try other format (e.g. MPEG)\n",
    "            fourcc=cv2.VideoWriter_fourcc(*codec),\n",
    "            fps=float(frames_per_second),\n",
    "            frameSize=(width, height),\n",
    "            isColor=True,\n",
    "        )\n",
    "    assert os.path.isfile(args.video_input)\n",
    "    for vis_frame in demo.run_on_video(video):\n",
    "        if args.output:\n",
    "            output_file.write(vis_frame)\n",
    "        else:\n",
    "            cv2.namedWindow(basename, cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow(basename, vis_frame)\n",
    "            if cv2.waitKey(1) == 27:\n",
    "                break  # esc to quit\n",
    "    video.release()\n",
    "    if args.output:\n",
    "        output_file.release()\n",
    "    else:\n",
    "        cv2.destroyAllWindows()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb82ae1f-bca7-4795-b1ed-418ef046469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.random_colors(N, rgb=False, maximum=255)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6738793-c95e-42d6-aaa0-846e13e4120d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reference\n",
    "\n",
    "```bibtex\n",
    "@inproceedings{zhou2022global,\n",
    "  title={Global Tracking Transformers},\n",
    "  author={Zhou, Xingyi and Yin, Tianwei and Koltun, Vladlen and Kr{\\\"a}henb{\\\"u}hl, Philipp},\n",
    "  booktitle={CVPR},\n",
    "  year={2022}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c75041-f23a-450f-8c0a-be19d5d1554c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearnear-gtr:Python",
   "language": "python",
   "name": "conda-env-machinelearnear-gtr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
